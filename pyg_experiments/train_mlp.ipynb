{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, random_split\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "import copy\n",
    "import numpy as np\n",
    "import multiprocessing as mp\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: 'cuda'\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: '{device}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_33107/1128881189.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  x_train = torch.load(f\"ds/mlp{year}{month}{perc}x_train.pt\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: torch.Size([863004, 85])\n",
      "x_test shape: torch.Size([50736, 85])\n",
      "y_train shape: torch.Size([863004])\n",
      "y_test shape: torch.Size([50736])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_33107/1128881189.py:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  x_test = torch.load(f\"ds/mlp{year}{month}{perc}x_test.pt\")\n",
      "/tmp/ipykernel_33107/1128881189.py:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  y_train = torch.load(f\"ds/mlp{year}{month}{perc}y_train.pt\")\n",
      "/tmp/ipykernel_33107/1128881189.py:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  y_test = torch.load(f\"ds/mlp{year}{month}{perc}y_test.pt\")\n"
     ]
    }
   ],
   "source": [
    "model_name = \"mlpnorm\"\n",
    "year = 2019\n",
    "month = 11\n",
    "perc = 0\n",
    "\n",
    "x_train = torch.load(f\"ds/mlp{year}{month}{perc}x_train.pt\")\n",
    "x_test = torch.load(f\"ds/mlp{year}{month}{perc}x_test.pt\")\n",
    "y_train = torch.load(f\"ds/mlp{year}{month}{perc}y_train.pt\")\n",
    "y_test = torch.load(f\"ds/mlp{year}{month}{perc}y_test.pt\")\n",
    "\n",
    "print(f\"x_train shape:\", x_train.shape)\n",
    "print(f\"x_test shape:\", x_test.shape)\n",
    "print(f\"y_train shape:\", y_train.shape)\n",
    "print(f\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_normalization(x_train, x_test):\n",
    "    mean = torch.mean(x_train, dim=0)\n",
    "    std = torch.std(x_train, dim=0)\n",
    "\n",
    "    x_train_normalized = (x_train - mean) / std\n",
    "    x_test_normalized = (x_test - mean) / std\n",
    "\n",
    "    return x_train_normalized, x_test_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_pca_explained_variance_normalized(x_train, x_test, target_variance=0.9):\n",
    "    # Calculate mean and standard deviation from training data\n",
    "    x_train_normalized, x_test_normalized = apply_normalization(x_train, x_test)\n",
    "\n",
    "    # Perform PCA with all components initially\n",
    "    U, S, V = torch.pca_lowrank(x_train_normalized)\n",
    "\n",
    "    # Calculate explained variance ratio\n",
    "    explained_variance_ratio = S**2 / torch.sum(S**2)\n",
    "    cumulative_variance_ratio = torch.cumsum(explained_variance_ratio, dim=0)\n",
    "\n",
    "    # Find the number of components to explain target variance\n",
    "    n_components = torch.argmax((cumulative_variance_ratio >= target_variance).int()) + 1\n",
    "\n",
    "    # Project the normalized data onto the selected components\n",
    "    x_train_pca = torch.matmul(x_train_normalized, V[:, :n_components])\n",
    "    x_test_pca = torch.matmul(x_test_normalized, V[:, :n_components])\n",
    "\n",
    "    return x_train_pca, x_test_pca, n_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_norm = True\n",
    "\n",
    "if apply_norm:\n",
    "    index_mask = [0, 1, 2, 8, *[i for i in range(15, 42)]]\n",
    "    index_mask += [i + 42 for i in index_mask] + [84]\n",
    "    keep_indexes = [i for i in range(x_train.shape[1]) if i not in index_mask]\n",
    "    x_train_norm, x_test_norm = apply_normalization(x_train[:, index_mask], x_test[:, index_mask])\n",
    "\n",
    "    new_x_train = torch.hstack([x_train_norm, x_train[:, keep_indexes]])\n",
    "    new_x_test = torch.hstack([x_test_norm, x_test[:, keep_indexes]])\n",
    "\n",
    "    x_train = new_x_train\n",
    "    x_test = new_x_test\n",
    "\n",
    "    print(new_x_train.shape)\n",
    "    print(new_x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of components used: 5\n",
      "torch.Size([863004, 27])\n",
      "torch.Size([50736, 27])\n"
     ]
    }
   ],
   "source": [
    "apply_PCA = False\n",
    "\n",
    "if apply_PCA:\n",
    "    index_mask = [0, 1, 2, 8, *[i for i in range(15, 42)]]\n",
    "    index_mask += [i + 42 for i in index_mask] + [84]\n",
    "    keep_indexes = [i for i in range(x_train.shape[1]) if i not in index_mask]\n",
    "    x_train_pca, x_test_pca, num_components_used = apply_pca_explained_variance_normalized(x_train[:, index_mask], x_test[:, index_mask], target_variance=0.9)\n",
    "\n",
    "    new_x_train = torch.hstack([x_train_pca, x_train[:, keep_indexes]])\n",
    "    new_x_test = torch.hstack([x_test_pca, x_test[:, keep_indexes]])\n",
    "\n",
    "    x_train = new_x_train\n",
    "    x_test = new_x_test\n",
    "\n",
    "    print(f\"Number of components used: {num_components_used}\")\n",
    "    print(new_x_train.shape)\n",
    "    print(new_x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latest epoch: 0\n",
      "Is trained? False\n"
     ]
    }
   ],
   "source": [
    "results_df = pd.read_csv(\"results.csv\", dtype={\n",
    "    \"model\": str,\n",
    "    \"year\": int,\n",
    "    \"month\": int,\n",
    "    \"perc\": float,\n",
    "    \"epoch\": int,\n",
    "    \"train_loss\": float,\n",
    "    \"val_loss\": float,\n",
    "    \"acc\": float,\n",
    "    \"prec\": float,\n",
    "    \"rec\": float,\n",
    "    \"f1\": float,\n",
    "    \"auc\": float,\n",
    "    \"tp\": int,\n",
    "    \"fp\": int,\n",
    "    \"fn\": int,\n",
    "    \"tn\": int,\n",
    "    \"best_threshold\": float,\n",
    "    \"done\": bool\n",
    "})\n",
    "\n",
    "filtered_df = results_df[\n",
    "    (results_df[\"model\"] == model_name) &\n",
    "    (results_df[\"year\"] == year) &\n",
    "    (results_df[\"month\"] == month) &\n",
    "    (results_df[\"perc\"] == perc)\n",
    "]\n",
    "\n",
    "if filtered_df.empty:\n",
    "    latest_epoch = 0\n",
    "    is_trained = False\n",
    "else:\n",
    "    latest_epoch = filtered_df[\"epoch\"].max()\n",
    "    is_trained = filtered_df[\"done\"].any()\n",
    "\n",
    "print(\"Latest epoch:\", latest_epoch)\n",
    "print(\"Is trained?\", is_trained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = x_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(x_train, y_train)\n",
    "test_dataset = TensorDataset(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8 * x_train.shape[0])\n",
    "val_size = x_train.shape[0] - train_size\n",
    "train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=10, pin_memory=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=128, num_workers=10, pin_memory=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=128, num_workers=10, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size: int):\n",
    "        super(MLP, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_size, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 1)\n",
    "        )\n",
    "        # self.layers = nn.Sequential(\n",
    "        #     nn.Linear(input_size, 128),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.Linear(128, 1),\n",
    "        # )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(threshold, all_probs, all_labels):\n",
    "    preds_binary = (all_probs > threshold).astype(int)\n",
    "    cm = confusion_matrix(all_labels, preds_binary)\n",
    "    tp = cm[1, 1]\n",
    "    fp = cm[0, 1]\n",
    "    fn = cm[1, 0]\n",
    "    tn = cm[0, 0]\n",
    "    precision = 0 if tp == 0 else tp / (tp + fp)\n",
    "    recall = 0 if tp == 0 else tp / (tp + fn)\n",
    "    f1 = 0 if precision * recall == 0 else 2 * precision * recall / (precision + recall)\n",
    "    return threshold, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, val_loader, optimizer, criterion, device, num_epochs, results_df, patience=5):\n",
    "    best_threshold = 0.0\n",
    "    best_val_f1 = 0.0\n",
    "    epochs_no_improve = 0\n",
    "    best_model_state = None\n",
    "    train_losses = list()\n",
    "    val_losses = list()\n",
    "    best_epoch = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "        model.train()  # Set model to training mode\n",
    "        train_loss = 0.0\n",
    "        for inputs, targets in tqdm.tqdm(train_loader):\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            optimizer.zero_grad()  # Zero the gradients\n",
    "            outputs = model(inputs).squeeze(1)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()  # Backpropagate the loss\n",
    "            optimizer.step()  # Update the weights\n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "        print(\"Train loss:\", train_loss)\n",
    "    \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        all_labels = []\n",
    "        all_probs = []  # Store probabilities for ROC-AUC\n",
    "        print(\"Validating...\")\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in tqdm.tqdm(val_loader):\n",
    "                inputs = inputs.to(device)\n",
    "                targets = targets.to(device)\n",
    "\n",
    "                outputs = model(inputs).squeeze(1)\n",
    "                loss = criterion(outputs, targets)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                # Get predictions and probabilities (assuming binary classification with sigmoid output)\n",
    "                probs = torch.sigmoid(outputs).cpu().numpy()  # Apply sigmoid if needed\n",
    "                labels = targets.cpu().numpy()\n",
    "\n",
    "                all_labels.extend(labels)\n",
    "                all_probs.extend(probs.flatten())\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "\n",
    "        # Find threshold for predictions\n",
    "        print(\"Looking for threshold\")\n",
    "\n",
    "        with mp.Pool(10) as pool:\n",
    "            results = pool.starmap(\n",
    "                calculate_metrics, \n",
    "                [\n",
    "                    (threshold, all_probs, all_labels)\n",
    "                    for threshold in np.arange(0.05, 0.96, 0.01)\n",
    "                ]\n",
    "            )\n",
    "\n",
    "        best_threshold_epoch = 0\n",
    "        best_f1_epoch = -1\n",
    "        for threshold, f1 in results:\n",
    "            if f1 > best_f1_epoch:\n",
    "                best_f1_epoch = f1\n",
    "                best_threshold_epoch = threshold\n",
    "\n",
    "        print(f\"Best threshold: {best_threshold_epoch}\")\n",
    "        all_preds = (all_probs > best_threshold_epoch).astype(int)\n",
    "\n",
    "        cm = confusion_matrix(all_labels, all_preds)\n",
    "        tp = cm[1, 1]\n",
    "        fp = cm[0, 1]\n",
    "        fn = cm[1, 0]\n",
    "        tn = cm[0, 0]\n",
    "\n",
    "        accuracy = (tp + tn) / (tp + fp + fn + tn) if (tp + fp + fn + tn) > 0 else 0.0 # Handle division by zero\n",
    "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "        f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0.0\n",
    "        roc_auc = roc_auc_score(all_labels, all_probs)\n",
    "\n",
    "        print(f\"Validation Metrics - Epoch {epoch+1}/{num_epochs}:\")\n",
    "        print(f\"Loss      :{val_loss:.4f}\")\n",
    "        print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "        print(f\"Precision: {precision:.4f}\")\n",
    "        print(f\"Recall:    {recall:.4f}\")\n",
    "        print(f\"F1-score:  {f1:.4f}\")\n",
    "        print(f\"ROC-AUC:   {roc_auc:.4f}\")\n",
    "        print(f\"Confusion Matrix:\\n{tp} {fn}\\n{fp} {tn}\")\n",
    "\n",
    "        new_row = pd.DataFrame(\n",
    "            {\n",
    "                \"model\": [model_name],\n",
    "                \"year\": [year],\n",
    "                \"month\": [month],\n",
    "                \"perc\": [perc],\n",
    "                \"epoch\": [latest_epoch + epoch + 1],\n",
    "                \"train_loss\": [train_loss],\n",
    "                \"val_loss\": [val_loss],\n",
    "                \"acc\": [accuracy],\n",
    "                \"prec\": [precision],\n",
    "                \"rec\": [recall],\n",
    "                \"f1\": [f1],\n",
    "                \"auc\": [roc_auc],\n",
    "                \"tp\": [tp],\n",
    "                \"fp\": [fp],\n",
    "                \"fn\": [fn],\n",
    "                \"tn\": [tn],\n",
    "                \"best_threshold\": [best_threshold_epoch],\n",
    "                \"done\": [False]\n",
    "            }\n",
    "        )\n",
    "        results_df = pd.concat([results_df, new_row], ignore_index=True)\n",
    "        results_df.to_csv(\"results.csv\", index=False)\n",
    "\n",
    "        torch.save(model.state_dict(), f\"./model_{model_name}_{year}_{month}_{perc}_{latest_epoch + epoch + 1}.pth\")\n",
    "\n",
    "        if f1 > best_val_f1:\n",
    "            best_val_f1 = f1\n",
    "            best_threshold = best_threshold_epoch\n",
    "            epochs_no_improve = 0\n",
    "            best_model_state = copy.deepcopy(model.state_dict())\n",
    "            best_epoch = latest_epoch + epoch + 1\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            if epochs_no_improve == patience:\n",
    "                print(f\"Early stopping!!!\")\n",
    "                print(f\"Early stopping!!!\")\n",
    "                print(f\"Early stopping!!!\")\n",
    "                print(\"Best epoch:\", best_epoch)\n",
    "                model.load_state_dict(best_model_state)\n",
    "                break\n",
    "    \n",
    "    return best_threshold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader, device, criterion, best_threshold):\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "    all_probs = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in tqdm.tqdm(test_loader):\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            outputs = model(inputs).squeeze(1)\n",
    "            loss = criterion(outputs, targets)  # Use criterion here\n",
    "            test_loss += loss.item()\n",
    "\n",
    "            probs = torch.sigmoid(outputs).cpu().numpy()  # Apply sigmoid if needed\n",
    "            preds = (probs > best_threshold).astype(int)  # Convert probabilities to predictions\n",
    "            labels = targets.cpu().numpy()\n",
    "\n",
    "            all_labels.extend(labels)\n",
    "            all_preds.extend(preds.flatten())\n",
    "            all_probs.extend(probs.flatten())\n",
    "\n",
    "    test_loss /= len(test_loader)\n",
    "\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    tp = cm[1, 1]\n",
    "    fp = cm[0, 1]\n",
    "    fn = cm[1, 0]\n",
    "    tn = cm[0, 0]\n",
    "\n",
    "    accuracy = (tp + tn) / (tp + fp + fn + tn) if (tp + fp + fn + tn) > 0 else 0.0\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0.0\n",
    "    try:\n",
    "      roc_auc = roc_auc_score(all_labels, all_probs)\n",
    "    except ValueError:\n",
    "        roc_auc = 0.0\n",
    "\n",
    "    print(f\"Test Metrics:\")\n",
    "    print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall:    {recall:.4f}\")\n",
    "    print(f\"F1-score:  {f1:.4f}\")\n",
    "    print(f\"ROC-AUC:   {roc_auc:.4f}\")\n",
    "    print(f\"Confusion Matrix:\\n{tp} {fn}\\n{fp} {tn}\")\n",
    "    print(f\"Test Loss: {test_loss:.4f}\") # Print the loss as well\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5394/5394 [00:08<00:00, 607.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.3675663983259415\n",
      "Validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1349/1349 [00:01<00:00, 944.50it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for threshold\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold: 0.44000000000000006\n",
      "Validation Metrics - Epoch 1/1000:\n",
      "Loss      :0.3491\n",
      "Accuracy:  0.8438\n",
      "Precision: 0.8301\n",
      "Recall:    0.8643\n",
      "F1-score:  0.8469\n",
      "ROC-AUC:   0.9241\n",
      "Confusion Matrix:\n",
      "74578 11706\n",
      "15262 71055\n",
      "Epoch 2/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5394/5394 [00:09<00:00, 589.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.3442218260971493\n",
      "Validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1349/1349 [00:01<00:00, 968.77it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for threshold\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold: 0.42000000000000004\n",
      "Validation Metrics - Epoch 2/1000:\n",
      "Loss      :0.3387\n",
      "Accuracy:  0.8499\n",
      "Precision: 0.8384\n",
      "Recall:    0.8667\n",
      "F1-score:  0.8523\n",
      "ROC-AUC:   0.9285\n",
      "Confusion Matrix:\n",
      "74784 11500\n",
      "14415 71902\n",
      "Epoch 3/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5394/5394 [00:08<00:00, 606.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.33699963819463474\n",
      "Validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1349/1349 [00:01<00:00, 984.79it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for threshold\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold: 0.43000000000000005\n",
      "Validation Metrics - Epoch 3/1000:\n",
      "Loss      :0.3352\n",
      "Accuracy:  0.8517\n",
      "Precision: 0.8418\n",
      "Recall:    0.8661\n",
      "F1-score:  0.8538\n",
      "ROC-AUC:   0.9299\n",
      "Confusion Matrix:\n",
      "74731 11553\n",
      "14042 72275\n",
      "Epoch 4/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5394/5394 [00:09<00:00, 569.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.3327221684917548\n",
      "Validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1349/1349 [00:01<00:00, 978.83it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for threshold\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold: 0.43000000000000005\n",
      "Validation Metrics - Epoch 4/1000:\n",
      "Loss      :0.3324\n",
      "Accuracy:  0.8528\n",
      "Precision: 0.8424\n",
      "Recall:    0.8679\n",
      "F1-score:  0.8550\n",
      "ROC-AUC:   0.9312\n",
      "Confusion Matrix:\n",
      "74882 11402\n",
      "14005 72312\n",
      "Epoch 5/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5394/5394 [00:09<00:00, 570.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.3292246349832726\n",
      "Validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1349/1349 [00:01<00:00, 948.36it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for threshold\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold: 0.39000000000000007\n",
      "Validation Metrics - Epoch 5/1000:\n",
      "Loss      :0.3307\n",
      "Accuracy:  0.8542\n",
      "Precision: 0.8453\n",
      "Recall:    0.8670\n",
      "F1-score:  0.8560\n",
      "ROC-AUC:   0.9325\n",
      "Confusion Matrix:\n",
      "74807 11477\n",
      "13691 72626\n",
      "Epoch 6/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5394/5394 [00:09<00:00, 568.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.32660850193275537\n",
      "Validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1349/1349 [00:01<00:00, 960.09it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for threshold\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold: 0.43000000000000005\n",
      "Validation Metrics - Epoch 6/1000:\n",
      "Loss      :0.3279\n",
      "Accuracy:  0.8544\n",
      "Precision: 0.8429\n",
      "Recall:    0.8710\n",
      "F1-score:  0.8567\n",
      "ROC-AUC:   0.9330\n",
      "Confusion Matrix:\n",
      "75154 11130\n",
      "14006 72311\n",
      "Epoch 7/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5394/5394 [00:08<00:00, 601.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.32442479533953805\n",
      "Validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1349/1349 [00:01<00:00, 960.80it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for threshold\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold: 0.42000000000000004\n",
      "Validation Metrics - Epoch 7/1000:\n",
      "Loss      :0.3248\n",
      "Accuracy:  0.8548\n",
      "Precision: 0.8385\n",
      "Recall:    0.8789\n",
      "F1-score:  0.8582\n",
      "ROC-AUC:   0.9343\n",
      "Confusion Matrix:\n",
      "75832 10452\n",
      "14609 71708\n",
      "Epoch 8/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5394/5394 [00:08<00:00, 607.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.32221601165563124\n",
      "Validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1349/1349 [00:01<00:00, 966.21it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for threshold\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold: 0.44000000000000006\n",
      "Validation Metrics - Epoch 8/1000:\n",
      "Loss      :0.3235\n",
      "Accuracy:  0.8568\n",
      "Precision: 0.8471\n",
      "Recall:    0.8707\n",
      "F1-score:  0.8587\n",
      "ROC-AUC:   0.9348\n",
      "Confusion Matrix:\n",
      "75130 11154\n",
      "13563 72754\n",
      "Epoch 9/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5394/5394 [00:10<00:00, 503.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.3207550944306694\n",
      "Validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1349/1349 [00:01<00:00, 926.64it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for threshold\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold: 0.4600000000000001\n",
      "Validation Metrics - Epoch 9/1000:\n",
      "Loss      :0.3217\n",
      "Accuracy:  0.8587\n",
      "Precision: 0.8522\n",
      "Recall:    0.8679\n",
      "F1-score:  0.8600\n",
      "ROC-AUC:   0.9355\n",
      "Confusion Matrix:\n",
      "74888 11396\n",
      "12987 73330\n",
      "Epoch 10/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5394/5394 [00:08<00:00, 638.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.31918521018261636\n",
      "Validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1349/1349 [00:01<00:00, 953.14it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for threshold\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold: 0.43000000000000005\n",
      "Validation Metrics - Epoch 10/1000:\n",
      "Loss      :0.3225\n",
      "Accuracy:  0.8575\n",
      "Precision: 0.8452\n",
      "Recall:    0.8753\n",
      "F1-score:  0.8600\n",
      "ROC-AUC:   0.9353\n",
      "Confusion Matrix:\n",
      "75524 10760\n",
      "13837 72480\n",
      "Epoch 11/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5394/5394 [00:08<00:00, 633.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.31755455920088055\n",
      "Validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1349/1349 [00:01<00:00, 937.38it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for threshold\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold: 0.43000000000000005\n",
      "Validation Metrics - Epoch 11/1000:\n",
      "Loss      :0.3210\n",
      "Accuracy:  0.8580\n",
      "Precision: 0.8464\n",
      "Recall:    0.8748\n",
      "F1-score:  0.8603\n",
      "ROC-AUC:   0.9358\n",
      "Confusion Matrix:\n",
      "75477 10807\n",
      "13696 72621\n",
      "Epoch 12/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5394/5394 [00:08<00:00, 633.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.31642417323215827\n",
      "Validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1349/1349 [00:01<00:00, 938.42it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for threshold\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold: 0.4000000000000001\n",
      "Validation Metrics - Epoch 12/1000:\n",
      "Loss      :0.3197\n",
      "Accuracy:  0.8582\n",
      "Precision: 0.8453\n",
      "Recall:    0.8767\n",
      "F1-score:  0.8607\n",
      "ROC-AUC:   0.9363\n",
      "Confusion Matrix:\n",
      "75647 10637\n",
      "13842 72475\n",
      "Epoch 13/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5394/5394 [00:09<00:00, 557.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.3152544028921661\n",
      "Validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1349/1349 [00:01<00:00, 959.62it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for threshold\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold: 0.4800000000000001\n",
      "Validation Metrics - Epoch 13/1000:\n",
      "Loss      :0.3191\n",
      "Accuracy:  0.8605\n",
      "Precision: 0.8539\n",
      "Recall:    0.8698\n",
      "F1-score:  0.8618\n",
      "ROC-AUC:   0.9369\n",
      "Confusion Matrix:\n",
      "75052 11232\n",
      "12839 73478\n",
      "Epoch 14/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5394/5394 [00:08<00:00, 633.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.31410894534921135\n",
      "Validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1349/1349 [00:01<00:00, 938.86it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for threshold\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold: 0.38000000000000006\n",
      "Validation Metrics - Epoch 14/1000:\n",
      "Loss      :0.3177\n",
      "Accuracy:  0.8597\n",
      "Precision: 0.8460\n",
      "Recall:    0.8794\n",
      "F1-score:  0.8624\n",
      "ROC-AUC:   0.9373\n",
      "Confusion Matrix:\n",
      "75878 10406\n",
      "13810 72507\n",
      "Epoch 15/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5394/5394 [00:08<00:00, 623.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.3132190177445726\n",
      "Validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1349/1349 [00:01<00:00, 963.37it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for threshold\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold: 0.4000000000000001\n",
      "Validation Metrics - Epoch 15/1000:\n",
      "Loss      :0.3172\n",
      "Accuracy:  0.8598\n",
      "Precision: 0.8474\n",
      "Recall:    0.8775\n",
      "F1-score:  0.8622\n",
      "ROC-AUC:   0.9374\n",
      "Confusion Matrix:\n",
      "75711 10573\n",
      "13633 72684\n",
      "Epoch 16/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5394/5394 [00:08<00:00, 631.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.31236873723188063\n",
      "Validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1349/1349 [00:01<00:00, 954.62it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for threshold\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold: 0.45000000000000007\n",
      "Validation Metrics - Epoch 16/1000:\n",
      "Loss      :0.3166\n",
      "Accuracy:  0.8605\n",
      "Precision: 0.8512\n",
      "Recall:    0.8737\n",
      "F1-score:  0.8623\n",
      "ROC-AUC:   0.9377\n",
      "Confusion Matrix:\n",
      "75386 10898\n",
      "13178 73139\n",
      "Epoch 17/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5394/5394 [00:09<00:00, 558.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.31129747880833386\n",
      "Validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1349/1349 [00:01<00:00, 947.78it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for threshold\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold: 0.49000000000000005\n",
      "Validation Metrics - Epoch 17/1000:\n",
      "Loss      :0.3178\n",
      "Accuracy:  0.8613\n",
      "Precision: 0.8599\n",
      "Recall:    0.8631\n",
      "F1-score:  0.8615\n",
      "ROC-AUC:   0.9375\n",
      "Confusion Matrix:\n",
      "74476 11808\n",
      "12139 74178\n",
      "Epoch 18/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5394/5394 [00:09<00:00, 560.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.31045321930955416\n",
      "Validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1349/1349 [00:01<00:00, 957.15it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for threshold\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold: 0.4000000000000001\n",
      "Validation Metrics - Epoch 18/1000:\n",
      "Loss      :0.3160\n",
      "Accuracy:  0.8601\n",
      "Precision: 0.8478\n",
      "Recall:    0.8777\n",
      "F1-score:  0.8625\n",
      "ROC-AUC:   0.9378\n",
      "Confusion Matrix:\n",
      "75734 10550\n",
      "13597 72720\n",
      "Epoch 19/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5394/5394 [00:09<00:00, 581.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.3095543066224081\n",
      "Validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1349/1349 [00:01<00:00, 944.33it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for threshold\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold: 0.37000000000000005\n",
      "Validation Metrics - Epoch 19/1000:\n",
      "Loss      :0.3190\n",
      "Accuracy:  0.8607\n",
      "Precision: 0.8526\n",
      "Recall:    0.8723\n",
      "F1-score:  0.8623\n",
      "ROC-AUC:   0.9376\n",
      "Confusion Matrix:\n",
      "75263 11021\n",
      "13014 73303\n",
      "Epoch 20/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5394/5394 [00:10<00:00, 532.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.30879150038743225\n",
      "Validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1349/1349 [00:01<00:00, 911.54it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for threshold\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold: 0.43000000000000005\n",
      "Validation Metrics - Epoch 20/1000:\n",
      "Loss      :0.3142\n",
      "Accuracy:  0.8625\n",
      "Precision: 0.8561\n",
      "Recall:    0.8713\n",
      "F1-score:  0.8636\n",
      "ROC-AUC:   0.9384\n",
      "Confusion Matrix:\n",
      "75179 11105\n",
      "12634 73683\n",
      "Epoch 21/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5394/5394 [00:09<00:00, 541.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.30812251668120916\n",
      "Validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1349/1349 [00:01<00:00, 940.13it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for threshold\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold: 0.43000000000000005\n",
      "Validation Metrics - Epoch 21/1000:\n",
      "Loss      :0.3131\n",
      "Accuracy:  0.8613\n",
      "Precision: 0.8518\n",
      "Recall:    0.8748\n",
      "F1-score:  0.8631\n",
      "ROC-AUC:   0.9388\n",
      "Confusion Matrix:\n",
      "75479 10805\n",
      "13137 73180\n",
      "Epoch 22/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5394/5394 [00:08<00:00, 651.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.30706378064212597\n",
      "Validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1349/1349 [00:01<00:00, 917.32it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for threshold\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold: 0.4000000000000001\n",
      "Validation Metrics - Epoch 22/1000:\n",
      "Loss      :0.3126\n",
      "Accuracy:  0.8616\n",
      "Precision: 0.8478\n",
      "Recall:    0.8814\n",
      "F1-score:  0.8643\n",
      "ROC-AUC:   0.9391\n",
      "Confusion Matrix:\n",
      "76053 10231\n",
      "13653 72664\n",
      "Epoch 23/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5394/5394 [00:10<00:00, 532.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.3063840119842914\n",
      "Validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1349/1349 [00:01<00:00, 921.16it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for threshold\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold: 0.43000000000000005\n",
      "Validation Metrics - Epoch 23/1000:\n",
      "Loss      :0.3140\n",
      "Accuracy:  0.8610\n",
      "Precision: 0.8507\n",
      "Recall:    0.8755\n",
      "F1-score:  0.8630\n",
      "ROC-AUC:   0.9384\n",
      "Confusion Matrix:\n",
      "75544 10740\n",
      "13255 73062\n",
      "Epoch 24/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5394/5394 [00:09<00:00, 560.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.30573106009594636\n",
      "Validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1349/1349 [00:01<00:00, 894.97it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for threshold\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold: 0.4700000000000001\n",
      "Validation Metrics - Epoch 24/1000:\n",
      "Loss      :0.3130\n",
      "Accuracy:  0.8623\n",
      "Precision: 0.8506\n",
      "Recall:    0.8790\n",
      "F1-score:  0.8646\n",
      "ROC-AUC:   0.9396\n",
      "Confusion Matrix:\n",
      "75842 10442\n",
      "13321 72996\n",
      "Epoch 25/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5394/5394 [00:09<00:00, 590.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.3049061662832763\n",
      "Validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1349/1349 [00:01<00:00, 910.81it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for threshold\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold: 0.42000000000000004\n",
      "Validation Metrics - Epoch 25/1000:\n",
      "Loss      :0.3139\n",
      "Accuracy:  0.8607\n",
      "Precision: 0.8470\n",
      "Recall:    0.8804\n",
      "F1-score:  0.8633\n",
      "ROC-AUC:   0.9385\n",
      "Confusion Matrix:\n",
      "75962 10322\n",
      "13726 72591\n",
      "Epoch 26/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5394/5394 [00:09<00:00, 585.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.30440104188667566\n",
      "Validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1349/1349 [00:01<00:00, 747.30it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for threshold\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold: 0.45000000000000007\n",
      "Validation Metrics - Epoch 26/1000:\n",
      "Loss      :0.3123\n",
      "Accuracy:  0.8621\n",
      "Precision: 0.8508\n",
      "Recall:    0.8781\n",
      "F1-score:  0.8642\n",
      "ROC-AUC:   0.9394\n",
      "Confusion Matrix:\n",
      "75767 10517\n",
      "13287 73030\n",
      "Epoch 27/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5394/5394 [00:08<00:00, 618.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.3037130754519755\n",
      "Validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1349/1349 [00:01<00:00, 907.80it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for threshold\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold: 0.4700000000000001\n",
      "Validation Metrics - Epoch 27/1000:\n",
      "Loss      :0.3140\n",
      "Accuracy:  0.8622\n",
      "Precision: 0.8531\n",
      "Recall:    0.8750\n",
      "F1-score:  0.8639\n",
      "ROC-AUC:   0.9390\n",
      "Confusion Matrix:\n",
      "75496 10788\n",
      "13003 73314\n",
      "Epoch 28/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5394/5394 [00:09<00:00, 567.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.30311931134607334\n",
      "Validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1349/1349 [00:01<00:00, 816.35it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for threshold\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold: 0.4700000000000001\n",
      "Validation Metrics - Epoch 28/1000:\n",
      "Loss      :0.3115\n",
      "Accuracy:  0.8633\n",
      "Precision: 0.8508\n",
      "Recall:    0.8812\n",
      "F1-score:  0.8657\n",
      "ROC-AUC:   0.9402\n",
      "Confusion Matrix:\n",
      "76034 10250\n",
      "13338 72979\n",
      "Epoch 29/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5394/5394 [00:09<00:00, 581.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.30256774597226316\n",
      "Validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1349/1349 [00:01<00:00, 874.73it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for threshold\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold: 0.4600000000000001\n",
      "Validation Metrics - Epoch 29/1000:\n",
      "Loss      :0.3109\n",
      "Accuracy:  0.8636\n",
      "Precision: 0.8538\n",
      "Recall:    0.8775\n",
      "F1-score:  0.8655\n",
      "ROC-AUC:   0.9402\n",
      "Confusion Matrix:\n",
      "75717 10567\n",
      "12970 73347\n",
      "Epoch 30/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5394/5394 [00:09<00:00, 566.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.3019932804171315\n",
      "Validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1349/1349 [00:01<00:00, 882.81it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for threshold\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold: 0.42000000000000004\n",
      "Validation Metrics - Epoch 30/1000:\n",
      "Loss      :0.3113\n",
      "Accuracy:  0.8630\n",
      "Precision: 0.8560\n",
      "Recall:    0.8727\n",
      "F1-score:  0.8643\n",
      "ROC-AUC:   0.9395\n",
      "Confusion Matrix:\n",
      "75303 10981\n",
      "12665 73652\n",
      "Epoch 31/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5394/5394 [00:09<00:00, 593.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.3014644068349146\n",
      "Validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1349/1349 [00:01<00:00, 843.11it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for threshold\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold: 0.39000000000000007\n",
      "Validation Metrics - Epoch 31/1000:\n",
      "Loss      :0.3124\n",
      "Accuracy:  0.8643\n",
      "Precision: 0.8603\n",
      "Recall:    0.8698\n",
      "F1-score:  0.8650\n",
      "ROC-AUC:   0.9402\n",
      "Confusion Matrix:\n",
      "75051 11233\n",
      "12192 74125\n",
      "Epoch 32/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5394/5394 [00:08<00:00, 602.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.3007806080649374\n",
      "Validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1349/1349 [00:01<00:00, 868.78it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for threshold\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold: 0.36000000000000004\n",
      "Validation Metrics - Epoch 32/1000:\n",
      "Loss      :0.3106\n",
      "Accuracy:  0.8627\n",
      "Precision: 0.8484\n",
      "Recall:    0.8832\n",
      "F1-score:  0.8654\n",
      "ROC-AUC:   0.9404\n",
      "Confusion Matrix:\n",
      "76205 10079\n",
      "13619 72698\n",
      "Epoch 33/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5394/5394 [00:09<00:00, 591.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.30015916174535273\n",
      "Validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1349/1349 [00:01<00:00, 890.11it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for threshold\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold: 0.43000000000000005\n",
      "Validation Metrics - Epoch 33/1000:\n",
      "Loss      :0.3097\n",
      "Accuracy:  0.8639\n",
      "Precision: 0.8557\n",
      "Recall:    0.8753\n",
      "F1-score:  0.8654\n",
      "ROC-AUC:   0.9402\n",
      "Confusion Matrix:\n",
      "75524 10760\n",
      "12737 73580\n",
      "Early stopping!!!\n",
      "Early stopping!!!\n",
      "Early stopping!!!\n",
      "Best epoch: 28\n"
     ]
    }
   ],
   "source": [
    "model = MLP(input_size).to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "best_threshold = train(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    optimizer,\n",
    "    criterion,\n",
    "    device,\n",
    "    1000,\n",
    "    results_df\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 397/397 [00:00<00:00, 544.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Metrics:\n",
      "Accuracy:  0.8327\n",
      "Precision: 0.8241\n",
      "Recall:    0.8460\n",
      "F1-score:  0.8349\n",
      "ROC-AUC:   0.9183\n",
      "Confusion Matrix:\n",
      "21461 3907\n",
      "4581 20787\n",
      "Test Loss: 0.3609\n"
     ]
    }
   ],
   "source": [
    "test(\n",
    "    model,\n",
    "    test_loader,\n",
    "    device,\n",
    "    criterion,\n",
    "    best_threshold\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "musicbrainz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
