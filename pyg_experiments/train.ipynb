{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31d33376",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import Tensor\n",
    "from torch.nn import Linear, ReLU, Sequential\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import HeteroData\n",
    "from torch_geometric.loader import LinkNeighborLoader\n",
    "from torch_geometric.nn import HeteroConv, GATConv, SAGEConv, Linear\n",
    "from torch_geometric.nn.aggr import Aggregation, MultiAggregation\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "from torch_geometric.typing import OptPairTensor, Adj, Size\n",
    "import os.path as path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "import tqdm\n",
    "from typing import Optional, Union, List, Tuple\n",
    "import matplotlib.pyplot as plt\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12322ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"ds/\"\n",
    "model_name = \"main\"\n",
    "year = 2019\n",
    "month = 11\n",
    "perc = 0\n",
    "train_hd = f\"train_hd_{year}_{month}_{perc}.pt\"\n",
    "# train_hd = f\"train_hd_nomatch_{year}_{month}_{perc}.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4d559d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latest epoch: 35\n",
      "Is trained? False\n"
     ]
    }
   ],
   "source": [
    "results_df = pd.read_csv(\"results.csv\", dtype={\n",
    "    \"model\": str,\n",
    "    \"year\": int,\n",
    "    \"month\": int,\n",
    "    \"perc\": float,\n",
    "    \"epoch\": int,\n",
    "    \"train_loss\": float,\n",
    "    \"val_loss\": float,\n",
    "    \"acc\": float,\n",
    "    \"prec\": float,\n",
    "    \"rec\": float,\n",
    "    \"f1\": float,\n",
    "    \"auc\": float,\n",
    "    \"tp\": int,\n",
    "    \"fp\": int,\n",
    "    \"fn\": int,\n",
    "    \"tn\": int,\n",
    "    \"best_threshold\": float,\n",
    "    \"done\": bool\n",
    "})\n",
    "\n",
    "filtered_df = results_df[\n",
    "    (results_df[\"model\"] == model_name) &\n",
    "    (results_df[\"year\"] == year) &\n",
    "    (results_df[\"month\"] == month) &\n",
    "    (results_df[\"perc\"] == perc)\n",
    "]\n",
    "\n",
    "if filtered_df.empty:\n",
    "    latest_epoch = 0\n",
    "    is_trained = False\n",
    "else:\n",
    "    latest_epoch = filtered_df[\"epoch\"].max()\n",
    "    is_trained = filtered_df[\"done\"].any()\n",
    "\n",
    "print(\"Latest epoch:\", latest_epoch)\n",
    "print(\"Is trained?\", is_trained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cdb5b1d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31800/2815972150.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data = torch.load(path.join(data_folder, train_hd))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = torch.load(path.join(data_folder, train_hd))\n",
    "\n",
    "data.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd6e6398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artist channels: 16\n",
      "Track channels: 5\n",
      "Tag channels: 24\n"
     ]
    }
   ],
   "source": [
    "artist_channels = data[\"artist\"].x.size(1)\n",
    "track_channels = data[\"track\"].x.size(1)\n",
    "tag_channels = data[\"tag\"].x.size(1)\n",
    "\n",
    "print(f\"Artist channels: {artist_channels}\")\n",
    "print(f\"Track channels: {track_channels}\")\n",
    "print(f\"Tag channels: {tag_channels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82faa4b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: 'cuda'\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "data[\"artist\", \"collab_with\", \"artist\"].edge_index = data[\"artist\", \"collab_with\", \"artist\"].edge_index.contiguous()\n",
    "\n",
    "print(f\"Device: '{device}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "956bf7d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating train_loader...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aleferu/miniforge3/envs/musicbrainz/lib/python3.12/site-packages/torch_geometric/sampler/neighbor_sampler.py:61: UserWarning: Using 'NeighborSampler' without a 'pyg-lib' installation is deprecated and will be removed soon. Please install 'pyg-lib' for accelerated neighborhood sampling\n",
      "  warnings.warn(f\"Using '{self.__class__.__name__}' without a \"\n"
     ]
    }
   ],
   "source": [
    "compt_tree_size = [25, 20]\n",
    "\n",
    "print(\"Creating train_loader...\")\n",
    "train_loader = LinkNeighborLoader(\n",
    "    data=data,\n",
    "    num_neighbors=compt_tree_size,\n",
    "    neg_sampling_ratio=1,\n",
    "    edge_label_index=(\"artist\", \"collab_with\", \"artist\"),\n",
    "    batch_size=128,\n",
    "    shuffle=True,\n",
    "    num_workers=10,\n",
    "    pin_memory=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e2d1165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11033\n",
      "2759\n"
     ]
    }
   ],
   "source": [
    "train_count = int(0.8 * len(train_loader))\n",
    "val_count = len(train_loader) - train_count\n",
    "\n",
    "print(train_count)\n",
    "print(val_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cfd307ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPSAGEConv(MessagePassing):\n",
    "    r\"\"\"The GraphSAGE operator with an MLP instead of the linear transformation.\n",
    "\n",
    "    Args:\n",
    "        in_channels (int or tuple): Size of each input sample, or :obj:`-1` to\n",
    "            derive the size from the first input(s) to the forward method.\n",
    "            A tuple corresponds to the sizes of source and target\n",
    "            dimensionalities.\n",
    "        out_channels (int): Size of each output sample.\n",
    "        hidden_channels (int, optional): Size of the hidden layer in the MLP.\n",
    "            (default: :obj:`64`)\n",
    "        aggr (str or Aggregation, optional): The aggregation scheme to use.\n",
    "            Any aggregation of :obj:`torch_geometric.nn.aggr` can be used,\n",
    "            *e.g.*, :obj:`\"mean\"`, :obj:`\"max\"`, or :obj:`\"lstm\"`.\n",
    "            (default: :obj:`\"mean\"`)\n",
    "        normalize (bool, optional): If set to :obj:`True`, output features\n",
    "            will be :math:`\\ell_2`-normalized, *i.e.*,\n",
    "            :math:`\\frac{\\mathbf{x}^{\\prime}_i}\n",
    "            {\\| \\mathbf{x}^{\\prime}_i \\|_2}`.\n",
    "            (default: :obj:`False`)\n",
    "        root_weight (bool, optional): If set to :obj:`False`, the layer will\n",
    "            not add transformed root node features to the output.\n",
    "            (default: :obj:`True`)\n",
    "        bias (bool, optional): If set to :obj:`False`, the layer will not learn\n",
    "            an additive bias. (default: :obj:`True`)\n",
    "        **kwargs (optional): Additional arguments of\n",
    "            :class:`torch_geometric.nn.conv.MessagePassing`.\n",
    "\n",
    "    Shapes:\n",
    "        - **inputs:**\n",
    "          node features :math:`(|\\mathcal{V}|, F_{in})` or\n",
    "          :math:`((|\\mathcal{V_s}|, F_{s}), (|\\mathcal{V_t}|, F_{t}))`\n",
    "          if bipartite,\n",
    "          edge indices :math:`(2, |\\mathcal{E}|)`\n",
    "        - **outputs:** node features :math:`(|\\mathcal{V}|, F_{out})` or\n",
    "          :math:`(|\\mathcal{V_t}|, F_{out})` if bipartite\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: Union[int, Tuple[int, int]],\n",
    "        out_channels: int,\n",
    "        hidden_channels: int = 64,\n",
    "        aggr: Optional[Union[str, List[str], Aggregation]] = \"mean\",\n",
    "        normalize: bool = False,\n",
    "        root_weight: bool = True,\n",
    "        bias: bool = True,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.hidden_channels = hidden_channels\n",
    "        self.normalize = normalize\n",
    "        self.root_weight = root_weight\n",
    "\n",
    "        if isinstance(in_channels, int):\n",
    "            in_channels = (in_channels, in_channels)\n",
    "\n",
    "        if aggr == \"lstm\":\n",
    "            kwargs.setdefault(\"aggr_kwargs\", {})\n",
    "            kwargs[\"aggr_kwargs\"].setdefault(\"in_channels\", in_channels[0])\n",
    "            kwargs[\"aggr_kwargs\"].setdefault(\"out_channels\", in_channels[0])\n",
    "\n",
    "        super().__init__(aggr, **kwargs)\n",
    "\n",
    "\n",
    "        self.mlp = Sequential(\n",
    "            Linear(in_channels[0], hidden_channels),\n",
    "            ReLU(),\n",
    "            Linear(hidden_channels, in_channels[0]) # Output size should match input for aggregation\n",
    "        )\n",
    "\n",
    "        if isinstance(self.aggr_module, MultiAggregation):\n",
    "            aggr_out_channels = self.aggr_module.get_out_channels(in_channels[0])\n",
    "        else:\n",
    "            aggr_out_channels = in_channels[0]\n",
    "\n",
    "        self.lin_l = Linear(aggr_out_channels, out_channels, bias=bias)\n",
    "        if self.root_weight:\n",
    "            self.lin_r = Linear(in_channels[1], out_channels, bias=False)\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        super().reset_parameters()\n",
    "        for layer in self.mlp:\n",
    "            if hasattr(layer, 'reset_parameters'):\n",
    "                layer.reset_parameters()\n",
    "        self.lin_l.reset_parameters()\n",
    "        if self.root_weight:\n",
    "            self.lin_r.reset_parameters()\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        x: Union[Tensor, OptPairTensor],\n",
    "        edge_index: Adj,\n",
    "        size: Size = None,\n",
    "    ) -> Tensor:\n",
    "\n",
    "        if isinstance(x, Tensor):\n",
    "            x = (x, x)\n",
    "\n",
    "        # Propagate through MLP\n",
    "        x = (self.mlp(x[0]), x[1])\n",
    "\n",
    "        # propagate_type: (x: OptPairTensor)\n",
    "        out = self.propagate(edge_index, x=x, size=size)\n",
    "        out = self.lin_l(out)\n",
    "\n",
    "        x_r = x[1]\n",
    "        if self.root_weight and x_r is not None:\n",
    "            out = out + self.lin_r(x_r)\n",
    "\n",
    "        if self.normalize:\n",
    "            out = F.normalize(out, p=2.0, dim=-1)\n",
    "\n",
    "        return out\n",
    "\n",
    "    def message(self, x_j: Tensor) -> Tensor:\n",
    "        return x_j\n",
    "\n",
    "    def message_and_aggregate(self, adj_t: Adj, x: OptPairTensor) -> Tensor:\n",
    "        if isinstance(adj_t, SparseTensor):\n",
    "            adj_t = adj_t.set_value(None, layout=None)\n",
    "        return spmm(adj_t, x[0], reduce=self.aggr)\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return (\n",
    "            f\"{self.__class__.__name__}({self.in_channels}, \"\n",
    "            f\"{self.out_channels}, hidden_channels={self.hidden_channels}, aggr={self.aggr})\"\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "91d598ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, metadata, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.metadata = metadata\n",
    "        self.out_channels = out_channels\n",
    "\n",
    "        self.conv1 = HeteroConv({\n",
    "            (\"artist\", \"collab_with\", \"artist\"): GATConv((artist_channels, artist_channels), hidden_channels),\n",
    "            (\"artist\", \"has_tag_artists\", \"tag\"): SAGEConv((artist_channels, tag_channels), hidden_channels),\n",
    "            # (\"artist\", \"last_fm_match\", \"artist\"): GATConv((artist_channels, artist_channels), hidden_channels),\n",
    "            (\"track\", \"has_tag_tracks\", \"tag\"): SAGEConv((track_channels, tag_channels), hidden_channels),\n",
    "            (\"artist\", \"linked_to\", \"artist\"): GATConv((artist_channels, artist_channels), hidden_channels),\n",
    "            (\"artist\", \"musically_related_to\", \"artist\"): GATConv((artist_channels, artist_channels), hidden_channels),\n",
    "            (\"artist\", \"personally_related_to\", \"artist\"): GATConv((artist_channels, artist_channels), hidden_channels),\n",
    "            (\"tag\", \"tags_artists\", \"artist\"): SAGEConv((tag_channels, artist_channels), hidden_channels),\n",
    "            (\"tag\", \"tags_tracks\", \"track\"): SAGEConv((tag_channels, track_channels), hidden_channels),\n",
    "            (\"track\", \"worked_by\", \"artist\"): SAGEConv((track_channels, artist_channels), hidden_channels),\n",
    "            (\"artist\", \"worked_in\", \"track\"): SAGEConv((artist_channels, track_channels), hidden_channels),\n",
    "        }, aggr=\"mean\")\n",
    "\n",
    "        self.conv2 = HeteroConv({\n",
    "            (\"artist\", \"collab_with\", \"artist\"): GATConv((hidden_channels, hidden_channels), hidden_channels),\n",
    "            (\"artist\", \"has_tag_artists\", \"tag\"): SAGEConv((hidden_channels, hidden_channels), hidden_channels),\n",
    "            # (\"artist\", \"last_fm_match\", \"artist\"): GATConv((hidden_channels, hidden_channels), hidden_channels),\n",
    "            (\"track\", \"has_tag_tracks\", \"tag\"): SAGEConv((hidden_channels, hidden_channels), hidden_channels),\n",
    "            (\"artist\", \"linked_to\", \"artist\"): GATConv((hidden_channels, hidden_channels), hidden_channels),\n",
    "            (\"artist\", \"musically_related_to\", \"artist\"): GATConv((hidden_channels, hidden_channels), hidden_channels),\n",
    "            (\"artist\", \"personally_related_to\", \"artist\"): GATConv((hidden_channels, hidden_channels), hidden_channels),\n",
    "            (\"tag\", \"tags_artists\", \"artist\"): SAGEConv((hidden_channels, hidden_channels), hidden_channels),\n",
    "            (\"tag\", \"tags_tracks\", \"track\"): SAGEConv((hidden_channels, hidden_channels), hidden_channels),\n",
    "            (\"track\", \"worked_by\", \"artist\"): SAGEConv((hidden_channels, hidden_channels), hidden_channels),\n",
    "            (\"artist\", \"worked_in\", \"track\"): SAGEConv((hidden_channels, hidden_channels), hidden_channels),\n",
    "        }, aggr=\"mean\")\n",
    "\n",
    "        self.linear1 = Linear(hidden_channels * 2, hidden_channels * 4)\n",
    "        self.linear2 = Linear(hidden_channels * 4, out_channels)\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict):\n",
    "        x_dict1 = self.conv1(x_dict, edge_index_dict)\n",
    "        x_dict2 = self.conv2(x_dict1, edge_index_dict)\n",
    "\n",
    "        x_artist = torch.cat([x_dict1['artist'], x_dict2['artist']], dim=-1)\n",
    "\n",
    "        x_artist = self.linear1(x_artist)\n",
    "        x_artist = self.linear2(x_artist)\n",
    "\n",
    "        # Normalize the artist node features\n",
    "        x_artist = F.normalize(x_artist, p=2, dim=-1)\n",
    "\n",
    "        # Update the dictionary with the new 'artist' features, leaving other nodes unchanged\n",
    "        x_dict['artist'] = x_artist\n",
    "\n",
    "        return x_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9525bb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, criterion, device, num_epochs, results_df, patience=5):\n",
    "    best_val_f1 = 0.0\n",
    "    best_threshold = 0\n",
    "    epochs_no_improve = 0\n",
    "    best_model_state = None\n",
    "    train_losses = list()\n",
    "    val_losses = list()\n",
    "    best_epoch = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set model to training mode\n",
    "        epoch_loss = 0.0\n",
    "        train_loader_iter = iter(train_loader)\n",
    "        \n",
    "        for i in tqdm.tqdm(range(train_count)):\n",
    "            # Move data to device\n",
    "            sampled_data = next(train_loader_iter).to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            pred_dict = model(sampled_data.x_dict, sampled_data.edge_index_dict)\n",
    "            \n",
    "            # Get predictions and labels for the 'collab_with' edge type\n",
    "            edge_label_index = sampled_data['artist', 'collab_with', 'artist'].edge_label_index\n",
    "            edge_label = sampled_data['artist', 'collab_with', 'artist'].edge_label\n",
    "\n",
    "            src_emb = pred_dict['artist'][edge_label_index[0]]  # Source node embeddings\n",
    "            dst_emb = pred_dict['artist'][edge_label_index[1]]  # Destination node embeddings\n",
    "            \n",
    "            # Compute the dot product between source and destination embeddings\n",
    "            preds = (src_emb * dst_emb).sum(dim=-1)  # Scalar for each edge\n",
    "            \n",
    "            # Compute loss\n",
    "            loss = criterion(preds, edge_label.float())\n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "            # Backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        # Average loss for the epoch\n",
    "        epoch_loss /= train_count\n",
    "        train_losses.append(epoch_loss)\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Training Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "        print(\"Computing validation metrics\")\n",
    "        \n",
    "        # Validation metrics\n",
    "        model.eval()  # Set model to evaluation mode\n",
    "        all_labels = []\n",
    "        all_probs = []\n",
    "        val_loss = 0.0\n",
    "        \n",
    "        with torch.no_grad():  # Disable gradient computation for validation\n",
    "            for i in tqdm.tqdm(range(val_count)):\n",
    "                # Move data to device\n",
    "                sampled_data = next(train_loader_iter).to(device)\n",
    "                \n",
    "                # Forward pass\n",
    "                pred_dict = model(sampled_data.x_dict, sampled_data.edge_index_dict)\n",
    "                \n",
    "                # Get predictions and labels for the 'collab_with' edge type\n",
    "                edge_label_index = sampled_data['artist', 'collab_with', 'artist'].edge_label_index\n",
    "                edge_label = sampled_data['artist', 'collab_with', 'artist'].edge_label\n",
    "\n",
    "                src_emb = pred_dict['artist'][edge_label_index[0]]  # Source node embeddings\n",
    "                dst_emb = pred_dict['artist'][edge_label_index[1]]  # Destination node embeddings\n",
    "                \n",
    "                # Compute the dot product between source and destination embeddings\n",
    "                preds = (src_emb * dst_emb).sum(dim=-1)  # Scalar for each edge\n",
    "\n",
    "                loss = criterion(preds, edge_label.float())\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                probs = torch.sigmoid(preds)  # Convert to probabilities\n",
    "                \n",
    "                # Collect predictions, probabilities, and labels\n",
    "                all_labels.append(edge_label.cpu())\n",
    "                all_probs.append(probs.cpu())\n",
    "        \n",
    "        # Concatenate all predictions and labels\n",
    "        all_labels = torch.cat(all_labels)\n",
    "        all_probs = torch.cat(all_probs)\n",
    "\n",
    "        val_loss /= val_count\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        # Find threshold for predictions\n",
    "        print(\"Looking for threshold\")\n",
    "        best_threshold_epoch = 0\n",
    "        best_f1_epoch = 0\n",
    "        for threshold in tqdm.tqdm(np.arange(0.2, 0.91, 0.01)):\n",
    "            preds_binary = (all_probs > threshold).long()\n",
    "            cm = confusion_matrix(all_labels, preds_binary)\n",
    "            tp = cm[1, 1]\n",
    "            fp = cm[0, 1]\n",
    "            fn = cm[1, 0]\n",
    "            tn = cm[0, 0]\n",
    "            precision = 0 if tp == 0 else tp / (tp + fp)\n",
    "            recall = 0 if tp == 0 else tp / (tp + fn)\n",
    "            f1 = 0 if precision * recall == 0 else 2 * precision * recall / (precision + recall)\n",
    "            if f1 > best_f1_epoch:\n",
    "                best_threshold_epoch = threshold\n",
    "                best_f1_epoch = f1\n",
    "        print(f\"Best threshold: {best_threshold_epoch}\")\n",
    "        all_preds = (all_probs > best_threshold_epoch).long()\n",
    "        \n",
    "        # Compute metrics\n",
    "        cm = confusion_matrix(all_labels, all_preds)\n",
    "        tp = cm[1, 1]\n",
    "        fp = cm[0, 1]\n",
    "        fn = cm[1, 0]\n",
    "        tn = cm[0, 0]\n",
    "        accuracy = (tp + tn) / (tp + fp + fn + tn)\n",
    "        precision = tp / (tp + fp)\n",
    "        recall = tp / (tp + fn)\n",
    "        f1 = 2 * precision * recall / (precision + recall)\n",
    "        roc_auc = roc_auc_score(all_labels, all_probs)\n",
    "        \n",
    "        # Print validation metrics\n",
    "        print(f\"Validation Metrics - Epoch {epoch+1}/{num_epochs}:\")\n",
    "        print(f\"Loss:      {val_loss:.4f}\")\n",
    "        print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "        print(f\"Precision: {precision:.4f}\")\n",
    "        print(f\"Recall:    {recall:.4f}\")\n",
    "        print(f\"F1-score:  {f1:.4f}\")\n",
    "        print(f\"ROC-AUC:   {roc_auc:.4f}\")\n",
    "        print(f\"Confusion Matrix:\\n{tp} {fn}\\n{fp} {tn}\")\n",
    "\n",
    "        new_row = pd.DataFrame(\n",
    "            {\n",
    "                \"model\": [model_name],\n",
    "                \"year\": [year],\n",
    "                \"month\": [month],\n",
    "                \"perc\": [perc],\n",
    "                \"epoch\": [latest_epoch + epoch + 1],\n",
    "                \"train_loss\": [epoch_loss],\n",
    "                \"val_loss\": [val_loss],\n",
    "                \"acc\": [accuracy],\n",
    "                \"prec\": [precision],\n",
    "                \"rec\": [recall],\n",
    "                \"f1\": [f1],\n",
    "                \"auc\": [roc_auc],\n",
    "                \"tp\": [tp],\n",
    "                \"fp\": [fp],\n",
    "                \"fn\": [fn],\n",
    "                \"tn\": [tn],\n",
    "                \"best_threshold\": [best_threshold_epoch],\n",
    "                \"done\": [False]\n",
    "            }\n",
    "        )\n",
    "        results_df = pd.concat([results_df, new_row], ignore_index=True)\n",
    "        results_df.to_csv(\"results.csv\", index=False)\n",
    "\n",
    "        torch.save(model.state_dict(), f\"./model_{model_name}_{year}_{month}_{perc}_{latest_epoch + epoch + 1}.pth\")\n",
    "\n",
    "        if f1 > best_val_f1:\n",
    "            best_val_f1 = f1\n",
    "            best_threshold = best_threshold_epoch\n",
    "            epochs_no_improve = 0\n",
    "            best_model_state = copy.deepcopy(model.state_dict())\n",
    "            best_epoch = latest_epoch + epoch + 1\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            if epochs_no_improve == patience:\n",
    "                print(f\"Early stopping!!!\")\n",
    "                print(f\"Early stopping!!!\")\n",
    "                print(f\"Early stopping!!!\")\n",
    "                print(\"Best epoch:\", best_epoch)\n",
    "                model.load_state_dict(best_model_state)\n",
    "                break\n",
    "\n",
    "    return best_threshold, train_losses, val_losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c71d770d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31800/3664580216.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  torch.load(\"model_main_nomatch_2019_11_0_35.pth\")\n",
      "100%|██████████| 11033/11033 [05:50<00:00, 31.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Training Loss: 0.5253\n",
      "Computing validation metrics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2759/2759 [01:09<00:00, 39.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for threshold\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [01:35<00:00,  1.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold: 0.6900000000000004\n",
      "Validation Metrics - Epoch 1/100:\n",
      "Loss:      0.5264\n",
      "Accuracy:  0.9202\n",
      "Precision: 0.8913\n",
      "Recall:    0.9571\n",
      "F1-score:  0.9230\n",
      "ROC-AUC:   0.9578\n",
      "Confusion Matrix:\n",
      "337931 15147\n",
      "41212 311866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11033/11033 [05:42<00:00, 32.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100, Training Loss: 0.5253\n",
      "Computing validation metrics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2759/2759 [01:09<00:00, 39.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for threshold\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [01:36<00:00,  1.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold: 0.6900000000000004\n",
      "Validation Metrics - Epoch 2/100:\n",
      "Loss:      0.5246\n",
      "Accuracy:  0.9145\n",
      "Precision: 0.8899\n",
      "Recall:    0.9461\n",
      "F1-score:  0.9171\n",
      "ROC-AUC:   0.9556\n",
      "Confusion Matrix:\n",
      "334060 19018\n",
      "41347 311731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11033/11033 [05:50<00:00, 31.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/100, Training Loss: 0.5252\n",
      "Computing validation metrics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2759/2759 [01:07<00:00, 41.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for threshold\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [01:33<00:00,  1.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold: 0.6800000000000004\n",
      "Validation Metrics - Epoch 3/100:\n",
      "Loss:      0.5253\n",
      "Accuracy:  0.9127\n",
      "Precision: 0.8848\n",
      "Recall:    0.9489\n",
      "F1-score:  0.9157\n",
      "ROC-AUC:   0.9532\n",
      "Confusion Matrix:\n",
      "335039 18039\n",
      "43630 309448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11033/11033 [05:33<00:00, 33.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/100, Training Loss: 0.5252\n",
      "Computing validation metrics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2759/2759 [01:11<00:00, 38.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for threshold\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [01:34<00:00,  1.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold: 0.6800000000000004\n",
      "Validation Metrics - Epoch 4/100:\n",
      "Loss:      0.5255\n",
      "Accuracy:  0.9111\n",
      "Precision: 0.8875\n",
      "Recall:    0.9416\n",
      "F1-score:  0.9137\n",
      "ROC-AUC:   0.9527\n",
      "Confusion Matrix:\n",
      "332447 20631\n",
      "42133 310945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11033/11033 [05:35<00:00, 32.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/100, Training Loss: 0.5249\n",
      "Computing validation metrics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2759/2759 [01:02<00:00, 44.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for threshold\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [01:35<00:00,  1.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold: 0.6700000000000004\n",
      "Validation Metrics - Epoch 5/100:\n",
      "Loss:      0.5257\n",
      "Accuracy:  0.9106\n",
      "Precision: 0.8791\n",
      "Recall:    0.9521\n",
      "F1-score:  0.9141\n",
      "ROC-AUC:   0.9529\n",
      "Confusion Matrix:\n",
      "336181 16897\n",
      "46254 306824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11033/11033 [05:43<00:00, 32.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/100, Training Loss: 0.5250\n",
      "Computing validation metrics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2759/2759 [01:01<00:00, 44.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for threshold\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [01:33<00:00,  1.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold: 0.6700000000000004\n",
      "Validation Metrics - Epoch 6/100:\n",
      "Loss:      0.5238\n",
      "Accuracy:  0.9110\n",
      "Precision: 0.8780\n",
      "Recall:    0.9547\n",
      "F1-score:  0.9147\n",
      "ROC-AUC:   0.9553\n",
      "Confusion Matrix:\n",
      "337078 16000\n",
      "46839 306239\n",
      "Early stopping!!!\n",
      "Early stopping!!!\n",
      "Early stopping!!!\n",
      "Best epoch: 36\n"
     ]
    }
   ],
   "source": [
    "model = GNN(metadata=data.metadata(), hidden_channels=64, out_channels=64).to(device)\n",
    "\n",
    "model.load_state_dict(\n",
    "    torch.load(\"model_main_nomatch_2019_11_0_35.pth\")\n",
    ")\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "best_threshold, train_losses, val_losses = train(\n",
    "    model,\n",
    "    train_loader,\n",
    "    optimizer,\n",
    "    F.binary_cross_entropy_with_logits,\n",
    "    device,\n",
    "    100,\n",
    "    results_df\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6f570fb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST THRESHOLD: 0.6900000000000004\n"
     ]
    }
   ],
   "source": [
    "print(\"BEST THRESHOLD:\", best_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9abe58c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_losses, label=\"Training loss\")\n",
    "plt.plot(val_losses, label=\"Validation loss\")\n",
    "\n",
    "plt.xticks(range(1, len(train_losses) + 1))\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0ebb80aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f\"./model_{model_name}_{year}_{month}_{perc}.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "musicbrainz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
