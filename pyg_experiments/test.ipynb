{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import Tensor\n",
    "from torch.nn import Linear, ReLU, Sequential\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import HeteroData\n",
    "from torch_geometric.loader import LinkNeighborLoader\n",
    "from torch_geometric.nn import HeteroConv, GATConv, SAGEConv, Linear\n",
    "from torch_geometric.nn.aggr import Aggregation, MultiAggregation\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "from torch_geometric.typing import OptPairTensor, Adj, Size\n",
    "import os.path as path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "import tqdm\n",
    "from typing import Optional, Union, List, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"ds/\"\n",
    "perc = 0.5\n",
    "year = 2019\n",
    "month = 11\n",
    "model_name = \"oneconv_mb\"\n",
    "# test_hd = f\"full_hd_nomatch_{perc}.pt\"\n",
    "# test_hd = f\"full_hd_{perc}.pt\"\n",
    "test_hd = f\"full_hdmb_{perc}.pt\"\n",
    "# train_collab_with_filename = f\"collab_with_nomatch_{year}_{month}_{perc}.pt\"\n",
    "# train_collab_with_filename = f\"collab_with_{year}_{month}_{perc}.pt\"\n",
    "train_collab_with_filename = f\"collab_withmb_{year}_{month}_{perc}.pt\"\n",
    "best_threshold = 0.72\n",
    "# model_path = f\"trained_models/model_main_nomatch_{year}_{month}_{perc}.pth\"\n",
    "# model_path = f\"model_main_{year}_{month}_{perc}.pth\"\n",
    "model_path = f\"trained_models/model_{model_name}_{year}_{month}_{perc}.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_122477/3886607939.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data = torch.load(path.join(data_folder, test_hd))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = torch.load(path.join(data_folder, test_hd))\n",
    "\n",
    "data.contiguous()\n",
    "\n",
    "data.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artist channels: 17\n",
      "Track channels: 5\n",
      "Tag channels: 24\n"
     ]
    }
   ],
   "source": [
    "artist_channels = data[\"artist\"].x.size(1)\n",
    "track_channels = data[\"track\"].x.size(1)\n",
    "tag_channels = data[\"tag\"].x.size(1)\n",
    "\n",
    "print(f\"Artist channels: {artist_channels}\")\n",
    "print(f\"Track channels: {track_channels}\")\n",
    "print(f\"Tag channels: {tag_channels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_122477/3191979287.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  train_collab_with = torch.load(path.join(data_folder, train_collab_with_filename))\n"
     ]
    }
   ],
   "source": [
    "train_collab_with = torch.load(path.join(data_folder, train_collab_with_filename))\n",
    "train_edges_set = set(map(tuple, train_collab_with.t().tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: 'cuda'\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: '{device}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating test_loader...\n"
     ]
    }
   ],
   "source": [
    "compt_tree_size = [25, 20]\n",
    "\n",
    "print(\"Creating test_loader...\")\n",
    "test_loader = LinkNeighborLoader(\n",
    "    data=data,\n",
    "    num_neighbors=compt_tree_size,\n",
    "    neg_sampling_ratio=1,\n",
    "    edge_label_index=(\"artist\", \"collab_with\", \"artist\"),\n",
    "    batch_size=128,\n",
    "    num_workers=10,\n",
    "    shuffle=False,\n",
    "    pin_memory=True,\n",
    "    subgraph_type=\"induced\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, metadata, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.metadata = metadata\n",
    "        self.out_channels = out_channels\n",
    "\n",
    "        self.conv1 = HeteroConv({\n",
    "            (\"artist\", \"collab_with\", \"artist\"): GATConv((artist_channels, artist_channels), hidden_channels, heads=3, concat=False),\n",
    "            (\"artist\", \"has_tag_artists\", \"tag\"): SAGEConv((artist_channels, tag_channels), hidden_channels, normalize=True, project=True),\n",
    "            # (\"artist\", \"last_fm_match\", \"artist\"): GATConv((artist_channels, artist_channels), hidden_channels, heads=3, concat=False),\n",
    "            (\"track\", \"has_tag_tracks\", \"tag\"): SAGEConv((track_channels, tag_channels), hidden_channels, normalize=True, project=True),\n",
    "            (\"artist\", \"linked_to\", \"artist\"): GATConv((artist_channels, artist_channels), hidden_channels, heads=3, concat=False),\n",
    "            (\"artist\", \"musically_related_to\", \"artist\"): GATConv((artist_channels, artist_channels), hidden_channels, heads=3, concat=False),\n",
    "            (\"artist\", \"personally_related_to\", \"artist\"): GATConv((artist_channels, artist_channels), hidden_channels, heads=3, concat=False),\n",
    "            (\"tag\", \"tags_artists\", \"artist\"): SAGEConv((tag_channels, artist_channels), hidden_channels, normalize=True, project=True),\n",
    "            (\"tag\", \"tags_tracks\", \"track\"): SAGEConv((tag_channels, track_channels), hidden_channels, normalize=True, project=True),\n",
    "            (\"track\", \"worked_by\", \"artist\"): SAGEConv((track_channels, artist_channels), hidden_channels, normalize=True, project=True),\n",
    "            (\"artist\", \"worked_in\", \"track\"): SAGEConv((artist_channels, track_channels), hidden_channels, normalize=True, project=True),\n",
    "        }, aggr=\"mean\")\n",
    "\n",
    "        self.conv2 = HeteroConv({\n",
    "            (\"artist\", \"collab_with\", \"artist\"): GATConv((hidden_channels, hidden_channels), hidden_channels, heads=3, concat=False),\n",
    "            (\"artist\", \"has_tag_artists\", \"tag\"): SAGEConv((hidden_channels, hidden_channels), hidden_channels, normalize=True, project=True),\n",
    "            # (\"artist\", \"last_fm_match\", \"artist\"): GATConv((hidden_channels, hidden_channels), hidden_channels, heads=3, concat=False),\n",
    "            (\"track\", \"has_tag_tracks\", \"tag\"): SAGEConv((hidden_channels, hidden_channels), hidden_channels, normalize=True, project=True),\n",
    "            (\"artist\", \"linked_to\", \"artist\"): GATConv((hidden_channels, hidden_channels), hidden_channels, heads=3, concat=False),\n",
    "            (\"artist\", \"musically_related_to\", \"artist\"): GATConv((hidden_channels, hidden_channels), hidden_channels, heads=3, concat=False),\n",
    "            (\"artist\", \"personally_related_to\", \"artist\"): GATConv((hidden_channels, hidden_channels), hidden_channels, heads=3, concat=False),\n",
    "            (\"tag\", \"tags_artists\", \"artist\"): SAGEConv((hidden_channels, hidden_channels), hidden_channels, normalize=True, project=True),\n",
    "            (\"tag\", \"tags_tracks\", \"track\"): SAGEConv((hidden_channels, hidden_channels), hidden_channels, normalize=True, project=True),\n",
    "            (\"track\", \"worked_by\", \"artist\"): SAGEConv((hidden_channels, hidden_channels), hidden_channels, normalize=True, project=True),\n",
    "            (\"artist\", \"worked_in\", \"track\"): SAGEConv((hidden_channels, hidden_channels), hidden_channels, normalize=True, project=True),\n",
    "        }, aggr=\"mean\")\n",
    "\n",
    "        self.linear1 = Linear(hidden_channels * 2, hidden_channels * 4)\n",
    "        self.linear2 = Linear(hidden_channels * 4, out_channels)\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict):\n",
    "        x_dict1 = self.conv1(x_dict, edge_index_dict)\n",
    "        x_dict2 = self.conv2(x_dict1, edge_index_dict)\n",
    "\n",
    "        x_artist = torch.cat([x_dict1['artist'], x_dict2['artist']], dim=-1)\n",
    "\n",
    "        x_artist = self.linear1(x_artist)\n",
    "        x_artist = F.relu(x_artist)\n",
    "        x_artist = self.linear2(x_artist)\n",
    "\n",
    "        # Normalize the artist node features\n",
    "        x_artist = F.normalize(x_artist, p=2, dim=-1)\n",
    "\n",
    "        # Update the dictionary with the new 'artist' features, leaving other nodes unchanged\n",
    "        x_dict['artist'] = x_artist\n",
    "\n",
    "        return x_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNN_NOCAT(torch.nn.Module):\n",
    "    def __init__(self, metadata, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.metadata = metadata\n",
    "        self.out_channels = out_channels\n",
    "\n",
    "        self.conv1 = HeteroConv({\n",
    "            (\"artist\", \"collab_with\", \"artist\"): GATConv((artist_channels, artist_channels), hidden_channels, heads=3, concat=False),\n",
    "            (\"artist\", \"has_tag_artists\", \"tag\"): SAGEConv((artist_channels, tag_channels), hidden_channels, normalize=True, project=True),\n",
    "            # (\"artist\", \"last_fm_match\", \"artist\"): GATConv((artist_channels, artist_channels), hidden_channels, heads=3, concat=False),\n",
    "            (\"track\", \"has_tag_tracks\", \"tag\"): SAGEConv((track_channels, tag_channels), hidden_channels, normalize=True, project=True),\n",
    "            (\"artist\", \"linked_to\", \"artist\"): GATConv((artist_channels, artist_channels), hidden_channels, heads=3, concat=False),\n",
    "            (\"artist\", \"musically_related_to\", \"artist\"): GATConv((artist_channels, artist_channels), hidden_channels, heads=3, concat=False),\n",
    "            (\"artist\", \"personally_related_to\", \"artist\"): GATConv((artist_channels, artist_channels), hidden_channels, heads=3, concat=False),\n",
    "            (\"tag\", \"tags_artists\", \"artist\"): SAGEConv((tag_channels, artist_channels), hidden_channels, normalize=True, project=True),\n",
    "            (\"tag\", \"tags_tracks\", \"track\"): SAGEConv((tag_channels, track_channels), hidden_channels, normalize=True, project=True),\n",
    "            (\"track\", \"worked_by\", \"artist\"): SAGEConv((track_channels, artist_channels), hidden_channels, normalize=True, project=True),\n",
    "            (\"artist\", \"worked_in\", \"track\"): SAGEConv((artist_channels, track_channels), hidden_channels, normalize=True, project=True),\n",
    "        }, aggr=\"mean\")\n",
    "\n",
    "        self.conv2 = HeteroConv({\n",
    "            (\"artist\", \"collab_with\", \"artist\"): GATConv((hidden_channels, hidden_channels), hidden_channels, heads=3, concat=False),\n",
    "            (\"artist\", \"has_tag_artists\", \"tag\"): SAGEConv((hidden_channels, hidden_channels), hidden_channels, normalize=True, project=True),\n",
    "            # (\"artist\", \"last_fm_match\", \"artist\"): GATConv((hidden_channels, hidden_channels), hidden_channels, heads=3, concat=False),\n",
    "            (\"track\", \"has_tag_tracks\", \"tag\"): SAGEConv((hidden_channels, hidden_channels), hidden_channels, normalize=True, project=True),\n",
    "            (\"artist\", \"linked_to\", \"artist\"): GATConv((hidden_channels, hidden_channels), hidden_channels, heads=3, concat=False),\n",
    "            (\"artist\", \"musically_related_to\", \"artist\"): GATConv((hidden_channels, hidden_channels), hidden_channels, heads=3, concat=False),\n",
    "            (\"artist\", \"personally_related_to\", \"artist\"): GATConv((hidden_channels, hidden_channels), hidden_channels, heads=3, concat=False),\n",
    "            (\"tag\", \"tags_artists\", \"artist\"): SAGEConv((hidden_channels, hidden_channels), hidden_channels, normalize=True, project=True),\n",
    "            (\"tag\", \"tags_tracks\", \"track\"): SAGEConv((hidden_channels, hidden_channels), hidden_channels, normalize=True, project=True),\n",
    "            (\"track\", \"worked_by\", \"artist\"): SAGEConv((hidden_channels, hidden_channels), hidden_channels, normalize=True, project=True),\n",
    "            (\"artist\", \"worked_in\", \"track\"): SAGEConv((hidden_channels, hidden_channels), hidden_channels, normalize=True, project=True),\n",
    "        }, aggr=\"mean\")\n",
    "\n",
    "        self.linear1 = Linear(hidden_channels, hidden_channels * 4)\n",
    "        self.linear2 = Linear(hidden_channels * 4, out_channels)\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict):\n",
    "        x_dict1 = self.conv1(x_dict, edge_index_dict)\n",
    "        x_dict2 = self.conv2(x_dict1, edge_index_dict)\n",
    "\n",
    "        # x_artist = torch.cat([x_dict1['artist'], x_dict2['artist']], dim=-1)\n",
    "\n",
    "        x_artist = self.linear1(x_dict2['artist'])\n",
    "        x_artist = F.relu(x_artist)\n",
    "        x_artist = self.linear2(x_artist)\n",
    "\n",
    "        # Normalize the artist node features\n",
    "        x_artist = F.normalize(x_artist, p=2, dim=-1)\n",
    "\n",
    "        # Update the dictionary with the new 'artist' features, leaving other nodes unchanged\n",
    "        x_dict['artist'] = x_artist\n",
    "\n",
    "        return x_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNN_ONECONV(torch.nn.Module):\n",
    "    def __init__(self, metadata, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.metadata = metadata\n",
    "        self.out_channels = out_channels\n",
    "\n",
    "        self.conv1 = HeteroConv({\n",
    "            (\"artist\", \"collab_with\", \"artist\"): GATConv((artist_channels, artist_channels), hidden_channels, heads=3, concat=False),\n",
    "            (\"artist\", \"has_tag_artists\", \"tag\"): SAGEConv((artist_channels, tag_channels), hidden_channels, normalize=True, project=True),\n",
    "            # (\"artist\", \"last_fm_match\", \"artist\"): GATConv((artist_channels, artist_channels), hidden_channels, heads=3, concat=False),\n",
    "            (\"track\", \"has_tag_tracks\", \"tag\"): SAGEConv((track_channels, tag_channels), hidden_channels, normalize=True, project=True),\n",
    "            (\"artist\", \"linked_to\", \"artist\"): GATConv((artist_channels, artist_channels), hidden_channels, heads=3, concat=False),\n",
    "            (\"artist\", \"musically_related_to\", \"artist\"): GATConv((artist_channels, artist_channels), hidden_channels, heads=3, concat=False),\n",
    "            (\"artist\", \"personally_related_to\", \"artist\"): GATConv((artist_channels, artist_channels), hidden_channels, heads=3, concat=False),\n",
    "            (\"tag\", \"tags_artists\", \"artist\"): SAGEConv((tag_channels, artist_channels), hidden_channels, normalize=True, project=True),\n",
    "            (\"tag\", \"tags_tracks\", \"track\"): SAGEConv((tag_channels, track_channels), hidden_channels, normalize=True, project=True),\n",
    "            (\"track\", \"worked_by\", \"artist\"): SAGEConv((track_channels, artist_channels), hidden_channels, normalize=True, project=True),\n",
    "            (\"artist\", \"worked_in\", \"track\"): SAGEConv((artist_channels, track_channels), hidden_channels, normalize=True, project=True),\n",
    "        }, aggr=\"mean\")\n",
    "\n",
    "        self.linear1 = Linear(hidden_channels, hidden_channels * 4)\n",
    "        self.linear2 = Linear(hidden_channels * 4, out_channels)\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict):\n",
    "        x_dict1 = self.conv1(x_dict, edge_index_dict)\n",
    "        # x_dict2 = self.conv2(x_dict1, edge_index_dict)\n",
    "\n",
    "        # x_artist = torch.cat([x_dict1['artist'], x_dict2['artist']], dim=-1)\n",
    "\n",
    "        x_artist = self.linear1(x_dict1['artist'])\n",
    "        x_artist = F.relu(x_artist)\n",
    "        x_artist = self.linear2(x_artist)\n",
    "\n",
    "        # Normalize the artist node features\n",
    "        x_artist = F.normalize(x_artist, p=2, dim=-1)\n",
    "\n",
    "        # Update the dictionary with the new 'artist' features, leaving other nodes unchanged\n",
    "        x_dict['artist'] = x_artist\n",
    "\n",
    "        return x_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNN_ONECONVONEFF(torch.nn.Module):\n",
    "    def __init__(self, metadata, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.metadata = metadata\n",
    "        self.out_channels = out_channels\n",
    "\n",
    "        self.conv1 = HeteroConv({\n",
    "            (\"artist\", \"collab_with\", \"artist\"): GATConv((artist_channels, artist_channels), hidden_channels, heads=3, concat=False),\n",
    "            (\"artist\", \"has_tag_artists\", \"tag\"): SAGEConv((artist_channels, tag_channels), hidden_channels, normalize=True, project=True),\n",
    "            # (\"artist\", \"last_fm_match\", \"artist\"): GATConv((artist_channels, artist_channels), hidden_channels, heads=3, concat=False),\n",
    "            (\"track\", \"has_tag_tracks\", \"tag\"): SAGEConv((track_channels, tag_channels), hidden_channels, normalize=True, project=True),\n",
    "            (\"artist\", \"linked_to\", \"artist\"): GATConv((artist_channels, artist_channels), hidden_channels, heads=3, concat=False),\n",
    "            (\"artist\", \"musically_related_to\", \"artist\"): GATConv((artist_channels, artist_channels), hidden_channels, heads=3, concat=False),\n",
    "            (\"artist\", \"personally_related_to\", \"artist\"): GATConv((artist_channels, artist_channels), hidden_channels, heads=3, concat=False),\n",
    "            (\"tag\", \"tags_artists\", \"artist\"): SAGEConv((tag_channels, artist_channels), hidden_channels, normalize=True, project=True),\n",
    "            (\"tag\", \"tags_tracks\", \"track\"): SAGEConv((tag_channels, track_channels), hidden_channels, normalize=True, project=True),\n",
    "            (\"track\", \"worked_by\", \"artist\"): SAGEConv((track_channels, artist_channels), hidden_channels, normalize=True, project=True),\n",
    "            (\"artist\", \"worked_in\", \"track\"): SAGEConv((artist_channels, track_channels), hidden_channels, normalize=True, project=True),\n",
    "        }, aggr=\"mean\")\n",
    "\n",
    "        self.linear = Linear(hidden_channels, hidden_channels)\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict):\n",
    "        x_dict1 = self.conv1(x_dict, edge_index_dict)\n",
    "        # x_dict2 = self.conv2(x_dict1, edge_index_dict)\n",
    "\n",
    "        # x_artist = torch.cat([x_dict1['artist'], x_dict2['artist']], dim=-1)\n",
    "\n",
    "        x_artist = self.linear(x_dict1['artist'])\n",
    "\n",
    "        # Normalize the artist node features\n",
    "        x_artist = F.normalize(x_artist, p=2, dim=-1)\n",
    "\n",
    "        # Update the dictionary with the new 'artist' features, leaving other nodes unchanged\n",
    "        x_dict['artist'] = x_artist\n",
    "\n",
    "        return x_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_122477/1963774615.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  torch.load(model_path)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GNN_ONECONV(\n",
       "  (conv1): HeteroConv(num_relations=10)\n",
       "  (linear1): Linear(64, 256, bias=True)\n",
       "  (linear2): Linear(256, 64, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model = GNN(metadata=data.metadata(), hidden_channels=64, out_channels=64).to(device)\n",
    "# model = GNN_NOCAT(metadata=data.metadata(), hidden_channels=64, out_channels=64).to(device)\n",
    "model = GNN_ONECONV(metadata=data.metadata(), hidden_channels=64, out_channels=64).to(device)\n",
    "model.load_state_dict(\n",
    "    torch.load(model_path)\n",
    ")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_loader, criterion, device, threshold, train_edges_set):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "    total_loss = 0.0\n",
    "    valid_batches = 0\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient computation\n",
    "        for sampled_data in tqdm.tqdm(test_loader):\n",
    "            # Move data to the device\n",
    "            sampled_data = sampled_data.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            pred_dict = model(sampled_data.x_dict, sampled_data.edge_index_dict)\n",
    "\n",
    "            # Get predictions and labels for the 'collab_with' edge type\n",
    "            edge_label_index = sampled_data['artist', 'collab_with', 'artist'].edge_label_index\n",
    "            edge_label = sampled_data['artist', 'collab_with', 'artist'].edge_label\n",
    "\n",
    "            # Filter edge list\n",
    "            filtered_edges = []\n",
    "            filtered_edge_label = []\n",
    "            positive_count = 0\n",
    "            for src, dst, label in zip(edge_label_index[0, :], edge_label_index[1, :], edge_label):\n",
    "                lookup_edge = (\n",
    "                    sampled_data['artist'].n_id[src].item(),\n",
    "                    sampled_data['artist'].n_id[dst].item()\n",
    "                )\n",
    "                if lookup_edge in train_edges_set:\n",
    "                    continue\n",
    "                label_item = label.item()\n",
    "\n",
    "                # Balancing\n",
    "                if np.isclose(label_item, 1):\n",
    "                    filtered_edge_label.append(label_item)\n",
    "                    filtered_edges.append([src.item(), dst.item()])\n",
    "                    positive_count += 1\n",
    "\n",
    "                elif positive_count > 0:\n",
    "                    filtered_edge_label.append(label_item)\n",
    "                    filtered_edges.append([src.item(), dst.item()])\n",
    "                    positive_count -= 1\n",
    "                else:\n",
    "                    break\n",
    "\n",
    "            if len(filtered_edges) == 0:\n",
    "                continue  # Skip if no valid edges left\n",
    "            \n",
    "            valid_batches += 1\n",
    "\n",
    "            # Normal evaluation with the rests\n",
    "            filtered_edges = torch.tensor(filtered_edges, dtype=torch.long).t().to(device)\n",
    "            filtered_labels = torch.tensor(filtered_edge_label).long().to(device)\n",
    "\n",
    "            src_emb = pred_dict['artist'][filtered_edges[0]]  # Source node embeddings\n",
    "            dst_emb = pred_dict['artist'][filtered_edges[1]]  # Destination node embeddings\n",
    "\n",
    "            # Compute the dot product between source and destination embeddings\n",
    "            preds = (src_emb * dst_emb).sum(dim=-1)  # Scalar for each edge\n",
    "            probs = torch.sigmoid(preds)  # Convert logits to probabilities\n",
    "            preds_binary = (probs > threshold).long()  # Convert probabilities to binary predictions\n",
    "\n",
    "            loss = criterion(preds, filtered_labels.float())\n",
    "            total_loss += loss\n",
    "\n",
    "            # Collect predictions and labels\n",
    "            all_preds.append(preds_binary.cpu())\n",
    "            all_labels.append(filtered_labels.cpu())\n",
    "            all_probs.append(probs.cpu())\n",
    "\n",
    "    # Concatenate all predictions and labels\n",
    "    all_preds = torch.cat(all_preds)\n",
    "    all_labels = torch.cat(all_labels)\n",
    "    all_probs = torch.cat(all_probs)\n",
    "        \n",
    "    # Average loss\n",
    "    total_loss /= valid_batches\n",
    "\n",
    "    # Compute metrics\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    tp = cm[1, 1]\n",
    "    fp = cm[0, 1]\n",
    "    fn = cm[1, 0]\n",
    "    tn = cm[0, 0]\n",
    "    accuracy = (tp + tn) / (tp + fp + fn + tn)\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    f1 = 2 * precision * recall / (precision + recall)\n",
    "    roc_auc = roc_auc_score(all_labels, all_probs)\n",
    "\n",
    "    print(\"Test Results:\")\n",
    "    print(f\"Loss:      {total_loss:.4f}\")\n",
    "    print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall:    {recall:.4f}\")\n",
    "    print(f\"F1-score:  {f1:.4f}\")\n",
    "    print(f\"ROC-AUC:   {roc_auc:.4f}\")\n",
    "    print(f\"Confusion Matrix:\\n{tp} {fn}\\n{fp} {tn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11171/11171 [08:26<00:00, 22.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Results:\n",
      "Loss:      0.5194\n",
      "Accuracy:  0.9331\n",
      "Precision: 0.8989\n",
      "Recall:    0.9759\n",
      "F1-score:  0.9358\n",
      "ROC-AUC:   0.9326\n",
      "Confusion Matrix:\n",
      "403130 9970\n",
      "45329 367771\n"
     ]
    }
   ],
   "source": [
    "test_model(\n",
    "    model,\n",
    "    test_loader, \n",
    "    F.binary_cross_entropy_with_logits,\n",
    "    device,\n",
    "    best_threshold,\n",
    "    train_edges_set\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "musicbrainz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
