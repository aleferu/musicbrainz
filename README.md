# MusicBrainz database study

This repository serves as a way of working with multiple computers and as a way of showing my work to the professor that guides me.

## .env file

A .env file is needed in order to configure the database connection. An example .env file is provided. Modify its contents to satisfy your needs.

## Dataset creation

They must be executed in the following order (the subitems are the files generated by the notebook):

- `mb_extraction/recordings_and_releases.ipynb`: Summary of all I've been learning/working on about `recordings`, `releases` and `tracks`, as well of the needed code to extract CSVs and some graphs.
    - `data/tracks-*.csv`, * being from 1 to 5.
- `mb_extraction/genres.ipynb`: Shows that the genre entity is useless in MB at the moment. At least I can't find a way of using it.
- `mb_extraction/various_artists_cleanup.py`: Script that merges the tracks CSVs while removing the artist with ID 1 ("Various Artists").
    - `data/tracks_no_va.csv`
- `mb_extraction/artist_artist.ipynb`: Shows how to generate CSVs containing information on relationships between artists and how to merge different instances of the same artist. It also exports all the information gathered until this point, but modified.
    - `data/artists.jsonl`
    - `data/relationships.csv`
    - `data/artist_tags.csv`
    - `data/tracks_no_va_merged.csv`
- `mb_extraction/relationships_cleanup.py`: Generates a version of the relationships CSV without duplicates.
    - `data/relationships_clean.csv`
- `pre_lfm/add_id_final_tracks_csv.py`: Adds an id column to `data/tracks_no_va_merged.csv` and modifies the data so that Neo4j won't complain.
    - `data/tracks_no_va_merged_id.csv`
- `pre_lfm/lastfm.ipynb`: Shows how we can use [last.fm](https://www.last.fm/)'s API and extract the information that holds.
- `pre_lfm/tags.ipynb`: Extracts MB's tags into a useful format for later use.
    - `data/tags.csv`
- `pre_lfm/clean_tags.py`: Using the information stored at the `util/` directory, this script filters the previously generated `tags.csv` and adapts the other CSVs.
    - `data/tags_clean.csv`
    - `data/artist_tags_clean.csv`
    - `data/tracks_no_va_merged_id_clean.csv` (That is getting ridiculous at this point, lol)
- `lfm/neo4j_import.py`: Imports our current dataset into a [Neo4j database](https://neo4j.com/).
    - From now on the idea is to never manage several files anymore and keep it in this Neo4j DB.
- `lfm/lastfm_*_extraction*.py`: Imports the information that we can extract from [last.fm](https://www.last.fm/)'s API into the [Neo4j database](https://neo4j.com/). Files used:
    - `lfm/lastfm_artist_extraction.py`
    - `lfm/lastfm_artist_extraction_cont.py`
    - `lfm/lastfm_track_extraction.py`
    - `lfm/lastfm_track_extraction_cont.py`
- `lfm/add_more_artist_info.py`: Extracts even more information related to artists in Musicbrainz and stores it in Neo4j.
- `lfm/pg_weight.py`: Adds a normalized weight field for all edges called `pg_weight`.

## Paper stats:

- `post_data/pg_clust_triangles_conncomp.py` for popularity and PageRank correlation, connected components, clustering coefficient and triangles.

## PyG experiments

Can be found at `pyg_experiments/`.

## Dates

- Musicbrainz data: `2024-10-31 21:00:49.130771+00`
- LastFM data: `2024-11-05` to `2024-11-23`.

## Stats

`schema.md` and `post_data/stats.ipynb` are dedicated to explain our dataset. With these two files you can learn about the root graph schema and check out some graphs and statistics.

`post_data/stats.ipynb` **is currently outdated.**

## Dependencies - conda

An `environment.yaml` is provided.

```bash
conda env create -f environment.yaml
```

Or with custom name.

```bash
conda env create -n customenvname -f environment.yaml
```

If pip fails install `pyg-lib` after everything else is done.

## PostgreSQL (MusicBrainz) database installation

I followed [this link](https://musicbrainz.org/doc/MusicBrainz_Server/Setup), section **Setup from source code**. In theory you can install the database without the web server but I didn't want to mess up by skipping a crucial step by accident. The web server installation is very fast, unlike the database installation, so I recommend doing it that way.

## Neo4j database installation

https://neo4j.com/docs/operations-manual/current/installation/linux/debian/


Configuration (added at the start of `/etc/neo4j/neo4j.conf`):

```
server.memory.heap.max_size=11G
server.memory.heap.initial_size=5G
dbms.security.auth_enabled=false
dbms.usage_report.enabled=false
dbms.security.procedures.unrestricted=apoc.*,gds.*
dbms.security.procedures.allowlist=apoc.*,gds.*
dbms.memory.transaction.total.max=10g
```

Configuration added to `/etc/neo4j/apoc.conf` (might need to create file):

```
apoc.import.file.enabled=true
```

`APOC` should already be downloaded somewhere in `/var/lib/neo4j/`, but you need to download and install `GDS` from [this link](https://neo4j.com/deployment-center/#gds-tab) (also check [version compatibilities](https://neo4j.com/docs/graph-data-science/current/installation/supported-neo4j-versions/) and [instructions](https://neo4j.com/docs/graph-data-science/current/installation/neo4j-server/)).

Then just `sudo neo4j start/stop/restart...` to run.

## LICENSE

No license right now as I don't know if this work can be exposed to the public at the moment of writing this README.
